{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark PJ\") \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set(\"spark.executor.memory\", \"32g\")\n",
    "spark.conf.set('spark.driver.memory','15g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data=[]\\nwith open(filePath, 'r') as f:    \\n    for i in range(75):\\n        f.readline()\\n    for i in range(12000000):\\n        data.append(f.readline().strip().split('\\t'))\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = \"./mernis/data_dump.sql\"\n",
    "# the method below is going to make your memory explode!!!\n",
    "\"\"\"data=[]\n",
    "with open(filePath, 'r') as f:    \n",
    "    for i in range(75):\n",
    "        f.readline()\n",
    "    for i in range(12000000):\n",
    "        data.append(f.readline().strip().split('\\t'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "data = sc.textFile(filePath,4).map(lambda l:l.split('\\t'))\n",
    "data = data.filter(lambda l: len(l)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=['uid', 'national_identifier', 'first_name', \"last_name\",'mother_first','father_first', 'gender', 'birth_city',\n",
    "'date_of_birth', 'id_registration_city', 'id_registration_district', 'address_city', 'address_district',\n",
    "'address_neighborhood', 'street_address', 'door_or_entrance_number', 'misc']\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(uid=u'291990', national_identifier=u'23480340824', first_name=u'NESLIHAN', last_name=u'ZENGIN', mother_first=u'ZEYCAN', father_first=u'OSMAN', gender=u'K', birth_city=u'KANGAL', date_of_birth=u'10/6/1978', id_registration_city=u'MALATYA', id_registration_district=u'KULUNCAK', address_city=u'MALATYA', address_district=u'KULUNCAK', address_neighborhood=u'ISMETPASA MAH.', street_address=u'BOGAZICI CADDESI', door_or_entrance_number=u'14', misc=u'<NULL>'),\n",
       " Row(uid=u'291991', national_identifier=u'17111553172', first_name=u'SADET', last_name=u'YILDIRIM', mother_first=u'ZOHRE', father_first=u'ISMAIL', gender=u'K', birth_city=u'MERSIN', date_of_birth=u'3/8/1949', id_registration_city=u'MALATYA', id_registration_district=u'KULUNCAK', address_city=u'MALATYA', address_district=u'KULUNCAK', address_neighborhood=u'ISMETPASA MAH.', street_address=u'CITILBAGI SOKAK', door_or_entrance_number=u'40', misc=u'<NULL>'),\n",
       " Row(uid=u'291992', national_identifier=u'10499773538', first_name=u'GONUL', last_name=u'CETIN', mother_first=u'ESME', father_first=u'HALIFE', gender=u'K', birth_city=u'KULUNCAK', date_of_birth=u'15/8/1987', id_registration_city=u'MALATYA', id_registration_district=u'AKCADAG', address_city=u'MALATYA', address_district=u'KULUNCAK', address_neighborhood=u'ISMETPASA MAH.', street_address=u'BOGAZICI CADDESI', door_or_entrance_number=u'2', misc=u'<NULL>'),\n",
       " Row(uid=u'291993', national_identifier=u'35995199842', first_name=u'MURAT', last_name=u'GENC', mother_first=u'ELIF', father_first=u'ISMAIL', gender=u'E', birth_city=u'CORUM', date_of_birth=u'23/4/1983', id_registration_city=u'CORUM', id_registration_district=u'CORUM MERKEZ', address_city=u'MALATYA', address_district=u'KULUNCAK', address_neighborhood=u'ISMETPASA MAH.', street_address=u'KALE SOKAK', door_or_entrance_number=u'23', misc=u'<NULL>'),\n",
       " Row(uid=u'291994', national_identifier=u'17417542900', first_name=u'SENEM', last_name=u'YILDIRIM', mother_first=u'SEDEF', father_first=u'MUSTAFA', gender=u'K', birth_city=u'ORTA OREN', date_of_birth=u'1/7/1936', id_registration_city=u'MALATYA', id_registration_district=u'KULUNCAK', address_city=u'MALATYA', address_district=u'KULUNCAK', address_neighborhood=u'ISMETPASA MAH.', street_address=u'CITILBAGI SOKAK', door_or_entrance_number=u'40', misc=u'<NULL>')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E1:统计土耳其公民中所有人中年龄最大的男人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|     uid|age|\n",
      "+--------+---+\n",
      "|30759557|701|\n",
      "|27821738|696|\n",
      "|29540857|693|\n",
      "|32198722|690|\n",
      "|24516674|689|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxAge = spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age FROM table ORDER BY age desc limit 5\")\n",
    "\n",
    "maxAge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(maxAge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2. 统计姓名中最常出现的字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'A', 82319942),\n",
       " (u'E', 56600565),\n",
       " (u'I', 49279256),\n",
       " (u'N', 37773093),\n",
       " (u'R', 35681543),\n",
       " (u'U', 34389962),\n",
       " (u'L', 32581810),\n",
       " (u'M', 29708399),\n",
       " (u'S', 29110326),\n",
       " (u'K', 27433586),\n",
       " (u'T', 24482238),\n",
       " (u'Y', 21262594),\n",
       " (u'C', 16788753),\n",
       " (u'H', 15947044),\n",
       " (u'O', 15731863),\n",
       " (u'D', 15259507),\n",
       " (u'G', 14257687),\n",
       " (u'Z', 14141151),\n",
       " (u'B', 10725429),\n",
       " (u'F', 7402885),\n",
       " (u'V', 4901782),\n",
       " (u'P', 3693601),\n",
       " (u'J', 134385),\n",
       " (u'.', 12177),\n",
       " (u'W', 1390),\n",
       " (u'-', 709),\n",
       " (u'X', 423),\n",
       " (u'Q', 205),\n",
       " (u'(', 175),\n",
       " (u')', 174)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name = spark.sql(\"SELECT first_name as fn, last_name as ln  FROM table\")\n",
    "def spl(x):\n",
    "    y=x.split()\n",
    "    z=list()\n",
    "    for i in y:\n",
    "        z.extend(list(i))\n",
    "    return z\n",
    "def spl2(x):\n",
    "    return x.split()\n",
    "name = spark.sql(\"SELECT concat(first_name , last_name) FROM table\")\n",
    "nameLetters=name.rdd.flatMap(lambda x:x).flatMap(lambda x:spl(x))\n",
    "\n",
    "sortByLetter=nameLetters.map(lambda x: (x, 1)). reduceByKey(lambda x,y: x+y). sortBy(lambda x: x[1], False)\n",
    "\n",
    "sortByLetter.take(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E3: 统计该国人又的年龄分布,年龄段分(0-18, 19-28, 29-38,39-48, 49-59,>60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select COUNT(*) from (SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age FROM table) as NEW WHERE NEW.age>=0 AND NEW.age<=18\").show()\n",
    "# spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age, COUNT(*) FROM table WHERE age>=19 AND age<=28\").show()\n",
    "# spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age, COUNT(*) FROM table WHERE age>=29 AND age<=38\").show()\n",
    "# spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age, COUNT(*) FROM table WHERE age>=39 AND age<=48\").show()\n",
    "# spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age, COUNT(*) FROM table WHERE age>=49 AND age<=59\").show()\n",
    "# spark.sql(\"SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age, COUNT(*) FROM table WHERE age>=60\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOTHER WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = spark.sql('SELECT uid,2019 - INT(SUBSTRING(date_of_birth,-4,4)) AS age FROM table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=0).filter(tmp.age<=18).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=0).filter(tmp.age<=18).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age| count|\n",
      "+---+------+\n",
      "| 28|349145|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=19).filter(tmp.age<=28).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349145"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=19).filter(tmp.age<=28).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|  count|\n",
      "+---+-------+\n",
      "| 31|1045151|\n",
      "| 34|1258091|\n",
      "| 37|1298211|\n",
      "| 35|1272332|\n",
      "| 38|1424503|\n",
      "| 29|1267091|\n",
      "| 32|1242773|\n",
      "| 33|1262629|\n",
      "| 30|1271867|\n",
      "| 36|1250523|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=29).filter(tmp.age<=38).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12593171"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=29).filter(tmp.age<=38).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|  count|\n",
      "+---+-------+\n",
      "| 44|1097350|\n",
      "| 47|1112227|\n",
      "| 40|1284212|\n",
      "| 48|1054244|\n",
      "| 41|1256054|\n",
      "| 43|1111588|\n",
      "| 39|1362790|\n",
      "| 45|1228699|\n",
      "| 42|1208954|\n",
      "| 46|1153070|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=39).filter(tmp.age<=48).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11869188"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=39).filter(tmp.age<=48).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|  count|\n",
      "+---+-------+\n",
      "| 53|1027736|\n",
      "| 52| 794745|\n",
      "| 57| 885179|\n",
      "| 54|1080864|\n",
      "| 55|1011845|\n",
      "| 59| 965010|\n",
      "| 49|1045109|\n",
      "| 51| 917911|\n",
      "| 50| 976998|\n",
      "| 56| 894883|\n",
      "| 58| 765783|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=49).filter(tmp.age<=59).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10366063"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=49).filter(tmp.age<=59).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age| count|\n",
      "+---+------+\n",
      "| 85|255012|\n",
      "| 65|699795|\n",
      "| 78|306263|\n",
      "|673|     5|\n",
      "|108|  2488|\n",
      "|683|     6|\n",
      "|101| 12725|\n",
      "|115|   375|\n",
      "| 81|314358|\n",
      "| 76|346370|\n",
      "|667|     1|\n",
      "|103|  8885|\n",
      "| 91|149804|\n",
      "|685|     1|\n",
      "|686|   155|\n",
      "|122|    22|\n",
      "|625|     2|\n",
      "| 93|123175|\n",
      "|111|   751|\n",
      "|665|     1|\n",
      "+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=60).groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14434140"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(tmp.age).filter(tmp.age>=60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E4: 按月份,统计该国人口生日在每个月上的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|birth_month| number|\n",
      "+-----------+-------+\n",
      "|       null|  61388|\n",
      "|          0|    673|\n",
      "|          1|7824976|\n",
      "|          2|4688993|\n",
      "|          3|5124982|\n",
      "|          4|4184062|\n",
      "|          5|4217321|\n",
      "|          6|3463381|\n",
      "|          7|4249153|\n",
      "|          8|3170640|\n",
      "|          9|3450705|\n",
      "|         10|3434428|\n",
      "|         11|2912085|\n",
      "|         12|2828919|\n",
      "|         14|      1|\n",
      "|         15|      2|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "birth=spark.sql(\"SELECT INT(split(date_of_birth,'/')[1]) as birth_month,COUNT(*) AS number FROM table GROUP BY birth_month ORDER BY birth_month\")\n",
    "birth.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E5: 统计一下该国的男女比例,男女人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|  number|\n",
      "+------+--------+\n",
      "|     K|25077226|\n",
      "|     E|24534483|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT gender,COUNT(*) AS number FROM table GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N1: 统计男性,女性最常见的10个姓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 女"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|last_name| count|\n",
      "+---------+------+\n",
      "|   YILMAZ|352338|\n",
      "|     KAYA|244272|\n",
      "|    DEMIR|231289|\n",
      "|    SAHIN|201958|\n",
      "|    CELIK|199622|\n",
      "|   YILDIZ|195162|\n",
      "| YILDIRIM|191966|\n",
      "|   OZTURK|178610|\n",
      "|    AYDIN|177894|\n",
      "|  OZDEMIR|164085|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT last_name,COUNT(*) AS count FROM table WHERE gender='E' GROUP BY last_name ORDER BY count DESC\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 男"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|last_name| count|\n",
      "+---------+------+\n",
      "|   YILMAZ|355954|\n",
      "|     KAYA|244100|\n",
      "|    DEMIR|230428|\n",
      "|    SAHIN|202155|\n",
      "|    CELIK|199330|\n",
      "|   YILDIZ|194060|\n",
      "| YILDIRIM|192835|\n",
      "|   OZTURK|180292|\n",
      "|    AYDIN|178501|\n",
      "|  OZDEMIR|165924|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT last_name,COUNT(*) AS count FROM table WHERE gender='K' GROUP BY last_name ORDER BY count DESC\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N2:统计每个城市市民的平均年龄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|id_registration_city|       average_age|\n",
      "+--------------------+------------------+\n",
      "|               ADANA|50.885431008504504|\n",
      "|             DENIZLI|53.521267682141875|\n",
      "|             TRABZON| 51.71044389796684|\n",
      "|           BALIKESIR| 54.65844873941054|\n",
      "|             BILECIK|54.640178202453306|\n",
      "|             GIRESUN|51.731187731298384|\n",
      "|              ARTVIN| 52.95359133390531|\n",
      "|           ZONGULDAK|51.628508505530554|\n",
      "|            ISTANBUL|55.974292262476624|\n",
      "|             ERZURUM| 49.56476601418911|\n",
      "|               IGDIR|48.583227637332406|\n",
      "|            NEVSEHIR|51.867912184651004|\n",
      "|              MANISA| 53.77766762080073|\n",
      "|              BITLIS|  46.6854444129062|\n",
      "|               BURSA| 53.82169031984749|\n",
      "|               IZMIR| 55.01943768982517|\n",
      "|                 VAN| 46.32588101800375|\n",
      "|             HAKKARI|45.711081303717094|\n",
      "|                BOLU| 53.81699284228758|\n",
      "|               CORUM|51.275606763278944|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT id_registration_city,AVG(2019 - INT(SUBSTRING(date_of_birth,-4,4))) AS average_age FROM table GROUP BY id_registration_city\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N3:说一下该国平均人口最年轻的5个城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|id_registration_city|       average_age|\n",
      "+--------------------+------------------+\n",
      "|             HAKKARI|45.711081303717094|\n",
      "|              SIRNAK| 45.84987434070204|\n",
      "|              BATMAN| 46.11198901177727|\n",
      "|                 VAN| 46.32588101800375|\n",
      "|                 MUS| 46.48979974733893|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT id_registration_city,AVG(2019 - INT(SUBSTRING(date_of_birth,-4,4))) AS average_age FROM table GROUP BY id_registration_city ORDER BY average_age ''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N4: 统计一下该国前10大人又城市中,每个城市的前3大姓氏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|id_registration_city| number|\n",
      "+--------------------+-------+\n",
      "|            ISTANBUL|1900634|\n",
      "|               KONYA|1557843|\n",
      "|               IZMIR|1473066|\n",
      "|              ANKARA|1287335|\n",
      "|               BURSA|1251065|\n",
      "|               SIVAS|1209830|\n",
      "|              SAMSUN|1195234|\n",
      "|               AYDIN|1186918|\n",
      "|               ADANA|1108354|\n",
      "|           SANLIURFA|1066305|\n",
      "|              MARDIN|1063690|\n",
      "|          DIYARBAKIR|1016653|\n",
      "|             ERZURUM|1010916|\n",
      "|              MANISA| 992523|\n",
      "|             TRABZON| 975134|\n",
      "|               HATAY| 956286|\n",
      "|                ORDU| 954541|\n",
      "|           BALIKESIR| 926511|\n",
      "|             KAYSERI| 889003|\n",
      "|              MERSIN| 878724|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popCity = spark.sql(\"SELECT id_registration_city,COUNT(*) AS number FROM table GROUP BY id_registration_city ORDER BY number DESC\")\n",
    "popCity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = popCity.rdd.flatMap(lambda x:x).take(20)\n",
    "#city=[i for i in d1.take(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'unicode'> ISTANBUL\n",
      "<type 'int'> 1900634\n",
      "<type 'unicode'> KONYA\n",
      "<type 'int'> 1557843\n",
      "<type 'unicode'> IZMIR\n",
      "<type 'int'> 1473066\n",
      "<type 'unicode'> ANKARA\n",
      "<type 'int'> 1287335\n",
      "<type 'unicode'> BURSA\n",
      "<type 'int'> 1251065\n",
      "<type 'unicode'> SIVAS\n",
      "<type 'int'> 1209830\n",
      "<type 'unicode'> SAMSUN\n",
      "<type 'int'> 1195234\n",
      "<type 'unicode'> AYDIN\n",
      "<type 'int'> 1186918\n",
      "<type 'unicode'> ADANA\n",
      "<type 'int'> 1108354\n",
      "<type 'unicode'> SANLIURFA\n",
      "<type 'int'> 1066305\n"
     ]
    }
   ],
   "source": [
    "for c in city:\n",
    "    print type(c), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTANBUL\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ|15025|\n",
      "|     KAYA| 8381|\n",
      "|   OZTURK| 7948|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "KONYA\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 2716|\n",
      "|    CELIK| 1861|\n",
      "|     KAYA| 1843|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "IZMIR\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 5355|\n",
      "|     KAYA| 3073|\n",
      "|   OZTURK| 2732|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "ANKARA\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ|10949|\n",
      "|    SAHIN| 7106|\n",
      "|   OZTURK| 6506|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "BURSA\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 4846|\n",
      "|    AYDIN| 3607|\n",
      "|   YILDIZ| 2867|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SIVAS\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 2985|\n",
      "| YILDIRIM| 2769|\n",
      "|   YILDIZ| 2691|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SAMSUN\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 3795|\n",
      "|    AYDIN| 2530|\n",
      "|    SAHIN| 2265|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "AYDIN\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 2754|\n",
      "|     KAYA| 2029|\n",
      "|    AYDIN| 1902|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "ADANA\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|   YILMAZ| 4812|\n",
      "|     KAYA| 3613|\n",
      "|    CELIK| 3297|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SANLIURFA\n",
      "+---------+-----+\n",
      "|last_name|count|\n",
      "+---------+-----+\n",
      "|    DEMIR|10792|\n",
      "|   CIFTCI| 8122|\n",
      "|     KAYA| 6336|\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in city:\n",
    "    if type(c)==int: continue\n",
    "    print(c)\n",
    "    sql_=\"SELECT last_name,COUNT(*) AS count FROM table WHERE id_registration_city='\"+str(c)+\"' GROUP BY last_name ORDER BY COUNT(*) DESC\"\n",
    "    spark.sql(sql_).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N5: 计算一下该国前10大人又城市中,每个城市的人口生日最集中分布的是哪2个月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTANBUL\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          7|232190|\n",
      "|          1|210683|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "KONYA\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|233455|\n",
      "|          3|160557|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "IZMIR\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|182326|\n",
      "|          7|160248|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "ANKARA\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|179389|\n",
      "|          3|135286|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "BURSA\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|159285|\n",
      "|          7|133978|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "SIVAS\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|162517|\n",
      "|          3|129923|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "SAMSUN\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|211699|\n",
      "|          3|122190|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "AYDIN\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|154536|\n",
      "|          3|120063|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "ADANA\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|213863|\n",
      "|          3|107823|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "SANLIURFA\n",
      "+-----------+------+\n",
      "|birth_month| count|\n",
      "+-----------+------+\n",
      "|          1|309939|\n",
      "|          2| 91797|\n",
      "+-----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in city:\n",
    "    if type(c)==int: continue\n",
    "    print(c)\n",
    "    sql_=\"SELECT INT(split(date_of_birth,'/')[1]) as birth_month,COUNT(*) AS count FROM table WHERE id_registration_city='\"+str(c)+\"' GROUP BY birth_month  ORDER BY COUNT(*) DESC\"\n",
    "    spark.sql(sql_).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N6: 统计一下，该国男、女最为常用的5个名字是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "+----------+-------+\n",
      "|first_name|  count|\n",
      "+----------+-------+\n",
      "|    MEHMET|1172949|\n",
      "|   MUSTAFA| 898640|\n",
      "|     AHMET| 719375|\n",
      "|       ALI| 663121|\n",
      "|   HUSEYIN| 521223|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "female\n",
      "+----------+-------+\n",
      "|first_name|  count|\n",
      "+----------+-------+\n",
      "|     FATMA|1154707|\n",
      "|      AYSE| 893025|\n",
      "|     EMINE| 756629|\n",
      "|    HATICE| 658979|\n",
      "|    ZEYNEP| 315488|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 男 E 女 K\n",
    "print(\"male\")\n",
    "spark.sql(\"SELECT first_name,COUNT(*) as count FROM table WHERE gender='E' GROUP BY first_name ORDER BY COUNT(*) DESC\").show(5)\n",
    "print(\"female\")\n",
    "spark.sql(\"SELECT first_name,COUNT(*) as count FROM table WHERE gender='K' GROUP BY first_name ORDER BY COUNT(*) DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N7: 计算一下该国前10大人又城市中，每个城市的最受欢迎的3个名字是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=[ 'ISTANBUL','KONYA','IZMIR','ANKARA','BURSA','SIVAS','SAMSUN', 'AYDIN', 'ADANA','SANLIURFA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTANBUL\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|     MURAT|18693|\n",
      "|   MUSTAFA|11684|\n",
      "|    MEHMET|10735|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "KONYA\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|   MUSTAFA| 9702|\n",
      "|    MEHMET| 9515|\n",
      "|      AYSE| 7442|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "IZMIR\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|     MURAT| 8508|\n",
      "|   MUSTAFA| 7388|\n",
      "|    MEHMET| 7280|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "ANKARA\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|     MURAT|14150|\n",
      "|   MUSTAFA| 9857|\n",
      "|    MEHMET| 8960|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "BURSA\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|   MUSTAFA| 5950|\n",
      "|    MEHMET| 5882|\n",
      "|     FATMA| 5810|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SIVAS\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|    HATICE| 3209|\n",
      "|   MUSTAFA| 2949|\n",
      "|     AHMET| 2901|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SAMSUN\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|     FATMA| 4325|\n",
      "|   MUSTAFA| 3910|\n",
      "|      AYSE| 3808|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "AYDIN\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|    MEHMET| 6928|\n",
      "|   MUSTAFA| 4981|\n",
      "|     FATMA| 4401|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "ADANA\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|    MEHMET| 9632|\n",
      "|   MUSTAFA| 7209|\n",
      "|     FATMA| 7083|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "SANLIURFA\n",
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|    MEHMET|15934|\n",
      "|     FATMA|11978|\n",
      "|     EMINE| 9739|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in city:\n",
    "    print(c)\n",
    "    sql_l=\"SELECT first_name,COUNT(*) AS count FROM table WHERE birth_city='\"+str(c)+\"' GROUP BY first_name ORDER BY COUNT(*) DESC\"\n",
    "    spark.sql(sql_l).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1. 构建人所在城市预测模型:根据给定一个人的所有信息(除了所在城市)，预测该人所在的 城市。分析该模型Top1到 Top 5的预测准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2. 性别预测模型:根据给定一个人的信息(除了性别)，能否出该人的性别?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  0|       a|\n",
      "|  1|       b|\n",
      "|  2|       c|\n",
      "|  3|       a|\n",
      "|  4|       a|\n",
      "|  5|       c|\n",
      "+---+--------+\n",
      "\n",
      "+---+--------+-------------+\n",
      "| id|category|categoryIndex|\n",
      "+---+--------+-------------+\n",
      "|  0|       a|          0.0|\n",
      "|  1|       b|          2.0|\n",
      "|  2|       c|          1.0|\n",
      "|  3|       a|          0.0|\n",
      "|  4|       a|          0.0|\n",
      "|  5|       c|          1.0|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "dddf = spark.createDataFrame([\n",
    "\n",
    "    (0, \"a\"), (1, \"b\"), \n",
    "\n",
    "    (2, \"c\"), (3, \"a\"), \n",
    "\n",
    "    (4, \"a\"), (5, \"c\")],\n",
    "\n",
    "    [\"id\", \"category\"])\n",
    "dddf.show()\n",
    "#创建StringIndexer对象，设定输入输出参数\n",
    "\n",
    "indexer =StringIndexer(inputCol ='category', outputCol= 'categoryIndex')\n",
    "\n",
    "#对这个DataFrame进行训练\n",
    "\n",
    "model = indexer.fit(dddf)\n",
    "\n",
    "#利用生成的模型对DataFrame进行transform操作\n",
    "\n",
    "indexed = model.transform(dddf)\n",
    "\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0, 0.0), (1, 2.0, 2.0), (2, 1.0, 1.0), (3, 0.0, 0.0), (4, 0.0, 0.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexed = StringIndexer(inputCol='category', outputCol= \"category_index\").fit(indexed).transform(indexed)\n",
    "# indexed.show()\n",
    "indexed = indexed.drop('category')\n",
    "rdd1 = indexed.rdd.map(tuple)\n",
    "rdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,0.0]),\n",
       " LabeledPoint(2.0, [1.0,2.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0]),\n",
       " LabeledPoint(0.0, [3.0,0.0]),\n",
       " LabeledPoint(0.0, [4.0,0.0]),\n",
       " LabeledPoint(1.0, [5.0,1.0])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelData1(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[1], row[0:1] + row[2:]))\n",
    "labelData1(rdd1).take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.select(F.collect_list('categoryIndex')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "row = Row(\"gender\", \"foo\", \"bar\")\n",
    "\n",
    "df = sc.parallelize([\n",
    "  row(\"0\", 3.0, DenseVector([0, 2.1, 'a'])),\n",
    "  row(\"1\", 1.0, DenseVector([0, 1.1, 'b'])),\n",
    "  row(\"1\", -1.0, DenseVector([0, 3.4, 'b'])),\n",
    "  row(\"0\", -3.0, DenseVector([0, 4.1, 'c']))\n",
    "]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uid',\n",
       " 'national_identifier',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'mother_first',\n",
       " 'father_first',\n",
       " 'gender',\n",
       " 'birth_city',\n",
       " 'date_of_birth',\n",
       " 'id_registration_city',\n",
       " 'id_registration_district',\n",
       " 'address_city',\n",
       " 'address_district',\n",
       " 'address_neighborhood',\n",
       " 'street_address',\n",
       " 'door_or_entrance_number',\n",
       " 'misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['uid',\n",
    " 'national_identifier',\n",
    " 'date_of_birth',\n",
    " 'id_registration_city',\n",
    " 'id_registration_district',\n",
    " 'address_city',\n",
    " 'address_district',\n",
    " 'address_neighborhood',\n",
    " 'street_address',\n",
    " 'door_or_entrance_number',\n",
    " 'misc']\n",
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------+------------+------+----------+\n",
      "|first_name|last_name|mother_first|father_first|gender|birth_city|\n",
      "+----------+---------+------------+------------+------+----------+\n",
      "|  NESLIHAN|   ZENGIN|      ZEYCAN|       OSMAN|     K|    KANGAL|\n",
      "+----------+---------+------------+------------+------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "leftCs=['first_name','last_name','mother_first','father_first','gender','birth_city']\n",
    "indexer = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in list(set(leftCs))]\n",
    "indexer\n",
    "\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------+------------+------+----------+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "|first_name|last_name|mother_first|father_first|gender|birth_city|father_first_index|first_name_index|last_name_index|gender_index|mother_first_index|birth_city_index|\n",
      "+----------+---------+------------+------------+------+----------+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "|  NESLIHAN|   ZENGIN|      ZEYCAN|       OSMAN|     K|    KANGAL|               8.0|           164.0|          150.0|         0.0|             450.0|           304.0|\n",
      "+----------+---------+------------+------------+------+----------+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*leftCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "|father_first_index|first_name_index|last_name_index|gender_index|mother_first_index|birth_city_index|\n",
      "+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "|               8.0|           164.0|          150.0|         0.0|             450.0|           304.0|\n",
      "+------------------+----------------+---------------+------------+------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "len(df.select(F.collect_list('father_first')).collect()[0][0])\n",
    "# df.select(F.max('father_first_index')).show()\n",
    "# df.select(F.max('first_name_index')).show()\n",
    "# df.select(F.max('last_name_index')).show()\n",
    "# df.select(F.max('mother_first_index')).show()\n",
    "# df.select(F.max('birth_city_index')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.select(F.collect_list('first_name')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.select(F.collect_list('last_name')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.select(F.collect_list('mother_first')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.select(F.collect_list('birth_city')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +-----------------------+\n",
    "# |max(father_first_index)|\n",
    "# +-----------------------+\n",
    "# |               206561.0|\n",
    "# +-----------------------+\n",
    "row = df.select(F.collect_list('father_first_index'),F.collect_list('first_name_index'),F.collect_list('last_name_index'),\n",
    "                F.collect_list('mother_first_index'),F.collect_list('birth_city_index')).collect()\n",
    "# print len(df.select(F.collect_list('first_name_index')).collect()[0][0])\n",
    "# print len(df.select(F.collect_list('last_name_index')).collect()[0][0])\n",
    "# print len(df.select(F.collect_list('mother_first_index')).collect()[0][0])\n",
    "# print len(df.select(F.collect_list('birth_city_index')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"训练模型\"\"\"\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "    \n",
    "def labelData(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[3], row[0:3] + row[4:]))\n",
    "\n",
    "training_data, validation_data, testing_data = labelData(df.rdd).randomSplit([0.7, 0.1 ,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [8.0,164.0,150.0,450.0,304.0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxBins=100)\n",
    "\n",
    "print(model.toDebugString())\n",
    "print('Feature 12:', CV_data.columns[12])\n",
    "print('Feature 4: ', CV_data.columns[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# data.groupBy('birth_month').count().orderBy(col('birth_month')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=birth.select(\"number\").rdd.flatMap(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=birth.select(\"birth_month\").rdd.flatMap(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=  np.array([c for c in month])\n",
    "y =  np.array([c for c in number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(birth_month=0, number=57),\n",
       " Row(birth_month=1, number=1531),\n",
       " Row(birth_month=2, number=952),\n",
       " Row(birth_month=3, number=1095),\n",
       " Row(birth_month=4, number=780)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=birth.rdd.map(lambda x:x)\n",
    "b.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有459个城市？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(list(df['birth_city'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data.groupBy('birth_city').count().orderBy(col('count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=d.select(\"birth_city\").rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=[i for i in d1.take(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+---+\n",
      "|first_name_gender|  E|  K|\n",
      "+-----------------+---+---+\n",
      "|       ELIF GAMZE|  0|  1|\n",
      "|         BELGUZAR|  0|  1|\n",
      "|  KADIR HAYRETTIN|  1|  0|\n",
      "|        MEVLUDUYE|  0|  1|\n",
      "|           EBUZER|  1|  0|\n",
      "|             UGUR| 13|  1|\n",
      "|            SENEM|  0| 18|\n",
      "|             EMEL|  0|  5|\n",
      "|            IDRIS|  2|  0|\n",
      "|             ZEKI|  7|  0|\n",
      "|         GULENBER|  0|  1|\n",
      "|           SEYCAN|  0|  1|\n",
      "|     HASAN TAHSIN|  1|  0|\n",
      "|           NURSEN|  0|  8|\n",
      "|            KAFUR|  1|  0|\n",
      "|         ALPASLAN|  2|  0|\n",
      "|         NURETTIN| 17|  0|\n",
      "|        ABDULGANI|  1|  0|\n",
      "|            MUSAB|  1|  0|\n",
      "|          GULUZAR|  0|  6|\n",
      "+-----------------+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.crosstab('first_name', 'gender').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
